{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/junhan/level4-nlp-finalproject-hackathon-nlp-01-lv3/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from modules.extra_utils import (get_video_info, change_fps, print_total_durations, extract_key_frames)\n",
    "from modules.utils import load_config\n",
    "from modules.scene_utils import (save_timestamps_to_txt, save_all_video_scenes_by_timestamps)\n",
    "from modules.audio_utils import (save_all_mono_audio_from_scene_folder, transcribe_and_save_scene_information_into_json)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config 파일을 로드\n",
    "config_path = \"./config/preprocessing_config.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "original_video_folder = config[\"general\"][\"video_folder\"]\n",
    "\n",
    "preprocessed_video_folder = config[\"scene_caption\"][\"fps_adjusted_video_folder\"]\n",
    "timestamp_file = config[\"scene_caption\"][\"timestamp_file\"]\n",
    "scene_folder = config[\"scene_caption\"][\"scene_folder\"]\n",
    "mono_audio_folder = config[\"scene_caption\"][\"audio\"][\"mono_audio_folder\"]\n",
    "\n",
    "key_frames_folder = config[\"frame_caption\"][\"key_frames_folder\"]\n",
    "\n",
    "video_files = [f for f in os.listdir(preprocessed_video_folder) if f.endswith(\".mp4\")]\n",
    "\n",
    "print(f\"[INFO] Configuration loaded successfully.\")\n",
    "print(f\"[INFO] Found {len(video_files)} video files in the input directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                      Resolution           FPS        Frames          Duration (s)   \n",
      "------------------------------------------------------------------------------------------\n",
      "-ncFDuKdgNE.mp4                640x360             23.976      3900            162.662        \n",
      "5qlG1ODkRWw.mp4                640x286             23.976      3474            144.895        \n",
      "6ZMZYrdXtP0.mp4                640x360             23.976      3660            152.652        \n",
      "7DfNc-wxnBM.mp4                640x360             23.976      3204            133.633        \n",
      "94AnEUa_z8U.mp4                640x360             23.976      3804            158.658        \n",
      "9iZFtT4aShI.mp4                640x360             23.976      3618            150.901        \n",
      "AHHH770W4Wk.mp4                640x360             23.976      3876            161.661        \n",
      "C4y_tu3LYlo.mp4                640x360             24.000      3197            133.208        \n",
      "Fz9HnTVx52g.mp4                640x360             23.976      3900            162.662        \n",
      "Pwv4avomXYo.mp4                640x360             23.976      3538            147.564        \n",
      "UdZuHyttXbw.mp4                640x360             23.976      3756            156.656        \n",
      "j8fcNsJOtQo.mp4                640x360             23.976      2977            124.166        \n",
      "mDUSjBiHYeY.mp4                640x360             23.976      3772            157.324        \n",
      "n1lbpj6868o.mp4                640x360             23.976      3804            158.658        \n",
      "oyYuYNnSq9E.mp4                640x360             23.976      3444            143.643        \n",
      "q-H62GgHjeg.mp4                640x360             23.976      4426            184.601        \n",
      "s2wBtcmE5W8.mp4                640x360             23.976      3780            157.657        \n",
      "tBDHJCVi7_0.mp4                640x360             23.976      3226            134.551        \n",
      "v8HrbX0hzX8.mp4                640x360             23.976      2916            121.621        \n",
      "wFtBmw4cINY.mp4                640x360             24.000      6070            252.917        \n",
      "xqsDUwDwdUM.mp4                640x360             23.976      3760            156.823        \n",
      "zjwBNUXCA-M.mp4                640x360             23.976      5004            208.708        \n"
     ]
    }
   ],
   "source": [
    "# 원본 비디오 파일의 정보를 출력\n",
    "get_video_info(original_video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processed and saved: ./preprocessed_video/7DfNc-wxnBM.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/s2wBtcmE5W8.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/6ZMZYrdXtP0.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/oyYuYNnSq9E.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/v8HrbX0hzX8.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/AHHH770W4Wk.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/tBDHJCVi7_0.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/C4y_tu3LYlo.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/94AnEUa_z8U.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/xqsDUwDwdUM.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/mDUSjBiHYeY.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/wFtBmw4cINY.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/9iZFtT4aShI.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/5qlG1ODkRWw.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/q-H62GgHjeg.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/j8fcNsJOtQo.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/UdZuHyttXbw.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/Pwv4avomXYo.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/n1lbpj6868o.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/-ncFDuKdgNE.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/zjwBNUXCA-M.mp4 with FPS 25\n",
      "[INFO] Processed and saved: ./preprocessed_video/Fz9HnTVx52g.mp4 with FPS 25\n"
     ]
    }
   ],
   "source": [
    "# FPS를 조정하여 preprocessed_video 폴더에 저장\n",
    "change_fps(original_video_folder, preprocessed_video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                      Resolution           FPS        Frames          Duration (s)   \n",
      "------------------------------------------------------------------------------------------\n",
      "-ncFDuKdgNE.mp4                640x360             25.000      3900            156.000        \n",
      "5qlG1ODkRWw.mp4                640x286             25.000      3474            138.960        \n",
      "6ZMZYrdXtP0.mp4                640x360             25.000      3660            146.400        \n",
      "7DfNc-wxnBM.mp4                640x360             25.000      3204            128.160        \n",
      "94AnEUa_z8U.mp4                640x360             25.000      3804            152.160        \n",
      "9iZFtT4aShI.mp4                640x360             25.000      3618            144.720        \n",
      "AHHH770W4Wk.mp4                640x360             25.000      3876            155.040        \n",
      "C4y_tu3LYlo.mp4                640x360             25.000      3197            127.880        \n",
      "Fz9HnTVx52g.mp4                640x360             25.000      3900            156.000        \n",
      "Pwv4avomXYo.mp4                640x360             25.000      3538            141.520        \n",
      "UdZuHyttXbw.mp4                640x360             25.000      3756            150.240        \n",
      "j8fcNsJOtQo.mp4                640x360             25.000      2977            119.080        \n",
      "mDUSjBiHYeY.mp4                640x360             25.000      3772            150.880        \n",
      "n1lbpj6868o.mp4                640x360             25.000      3804            152.160        \n",
      "oyYuYNnSq9E.mp4                640x360             25.000      3444            137.760        \n",
      "q-H62GgHjeg.mp4                640x360             25.000      4426            177.040        \n",
      "s2wBtcmE5W8.mp4                640x360             25.000      3780            151.200        \n",
      "tBDHJCVi7_0.mp4                640x360             25.000      3226            129.040        \n",
      "v8HrbX0hzX8.mp4                640x360             25.000      2916            116.640        \n",
      "wFtBmw4cINY.mp4                640x360             25.000      6070            242.800        \n",
      "xqsDUwDwdUM.mp4                640x360             25.000      3760            150.400        \n",
      "zjwBNUXCA-M.mp4                640x360             25.000      5004            200.160        \n"
     ]
    }
   ],
   "source": [
    "# FPS 조정된 비디오의 정보를 출력 (프레임 수 동일)\n",
    "get_video_info(preprocessed_video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "타임스탬프를 추출하여 txt 파일에 저장하는 중: 100%|██████████| 22/22 [00:47<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scene timestamps have been saved to ./timestamps.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 비디오 폴더의 모든 비디오에 대해 타임스탬프 추출하여 txt 파일로 저장\n",
    "save_timestamps_to_txt(\n",
    "    preprocessed_video_folder,\n",
    "    timestamp_file,\n",
    "    threshold=config[\"scene_caption\"][\"PySceneDetect_threshold\"],\n",
    "    min_scene_len=config[\"scene_caption\"][\"PySceneDetect_min_scene_len\"]\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Scene timestamps have been saved to {timestamp_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 22/22 [06:33<00:00, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scenes have been successfully split and saved to ./scenes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 타임스탬프 txt 파일로부터 비디오 Scene(mp4) 추출하여 scene_folder에 저장\n",
    "# 속도 향상을 위해 멀티프로세싱 사용하여 처리 순서가 순서대로가 아님. (tqdm 시간측정도 일관되지 않음) (6분 33초 소요)\n",
    "save_all_video_scenes_by_timestamps(\n",
    "    preprocessed_video_folder, scene_folder, timestamp_file\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Scenes have been successfully split and saved to {scene_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving mono audio: 100%|██████████| 650/650 [00:48<00:00, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Audio has been successfully extracted and saved to mono_audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Scene 폴더로부터 모든 Scene들의 모노 오디오를 mono_audio_folder에 저장\n",
    "save_all_mono_audio_from_scene_folder(scene_folder, mono_audio_folder)\n",
    "\n",
    "print(f\"[INFO] Audio has been successfully extracted and saved to {mono_audio_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SST model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/junhan/level4-nlp-finalproject-hackathon-nlp-01-lv3/.venv/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "100%|██████████| 22/22 [09:56<00:00, 27.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to scene_info_with_audio_scripts.json\n",
      "[INFO] Successfully transcribed and saved to scene_info_with_audio_scripts.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mono_audio_folder에 저장된 모든 Scene의 오디오를 텍스트로 변환하여 Scene 정보 JSON 파일로 저장\n",
    "transcribe_and_save_scene_information_into_json(\n",
    "    mono_audio_folder, config['scene_caption']['audio']['scene_info_with_audio_scripts_file'], timestamp_file\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Successfully transcribed and saved to {config['scene_caption']['audio']['scene_info_with_audio_scripts_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:   5%|▍         | 1/22 [01:28<30:57, 88.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 7DfNc-wxnBM: Extracted 82 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:   9%|▉         | 2/22 [03:12<32:30, 97.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] s2wBtcmE5W8: Extracted 49 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  14%|█▎        | 3/22 [04:52<31:15, 98.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 6ZMZYrdXtP0: Extracted 25 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  18%|█▊        | 4/22 [06:27<29:10, 97.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] oyYuYNnSq9E: Extracted 20 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  23%|██▎       | 5/22 [07:45<25:32, 90.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] v8HrbX0hzX8: Extracted 87 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  27%|██▋       | 6/22 [09:31<25:31, 95.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AHHH770W4Wk: Extracted 53 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  32%|███▏      | 7/22 [10:51<22:39, 90.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tBDHJCVi7_0: Extracted 139 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  36%|███▋      | 8/22 [12:19<20:58, 89.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] C4y_tu3LYlo: Extracted 46 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  41%|████      | 9/22 [14:04<20:28, 94.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 94AnEUa_z8U: Extracted 56 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  45%|████▌     | 10/22 [15:47<19:23, 96.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] xqsDUwDwdUM: Extracted 52 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  50%|█████     | 11/22 [17:30<18:07, 98.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] mDUSjBiHYeY: Extracted 58 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  55%|█████▍    | 12/22 [20:11<19:38, 117.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] wFtBmw4cINY: Extracted 83 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  59%|█████▉    | 13/22 [21:43<16:30, 110.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 9iZFtT4aShI: Extracted 118 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  64%|██████▎   | 14/22 [23:12<13:48, 103.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5qlG1ODkRWw: Extracted 121 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  68%|██████▊   | 15/22 [25:13<12:42, 109.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] q-H62GgHjeg: Extracted 15 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  73%|███████▎  | 16/22 [26:33<10:00, 100.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] j8fcNsJOtQo: Extracted 77 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  77%|███████▋  | 17/22 [28:15<08:23, 100.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] UdZuHyttXbw: Extracted 28 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  82%|████████▏ | 18/22 [29:51<06:37, 99.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pwv4avomXYo: Extracted 61 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  86%|████████▋ | 19/22 [31:36<05:02, 100.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] n1lbpj6868o: Extracted 86 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  91%|█████████ | 20/22 [33:24<03:26, 103.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -ncFDuKdgNE: Extracted 37 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중:  95%|█████████▌| 21/22 [35:39<01:52, 112.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] zjwBNUXCA-M: Extracted 60 key frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키 프레임 추출 중: 100%|██████████| 22/22 [37:26<00:00, 102.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fz9HnTVx52g: Extracted 49 key frames.\n",
      "[INFO] Key frames have been successfully extracted and saved to ./key_frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# CLIP 모델과 Processor를 로드\n",
    "model_path = 'openai/clip-vit-large-patch14'\n",
    "processor = CLIPProcessor.from_pretrained(model_path)\n",
    "clip_model = CLIPModel.from_pretrained(model_path).cuda()\n",
    "clip_model.requires_grad_(False)\n",
    "\n",
    "# 각 비디오에서 Key Frame을 추출하여 key_frames_folder에 저장\n",
    "for video_file in tqdm(video_files, desc=\"키 프레임 추출 중\"):\n",
    "    video_path = os.path.join(preprocessed_video_folder, video_file)\n",
    "    extract_key_frames(video_path, key_frames_folder, processor, clip_model, similarity_threshold=0.85, stddev_threshold=10)\n",
    "\n",
    "print(f\"[INFO] Key frames have been successfully extracted and saved to {key_frames_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total video duration: 0h 55m 24s 240ms\n",
      "[INFO] Total scene duration: 0h 55m 24s 240ms\n",
      "[INFO] Total audio duration: 0h 55m 24s 240ms\n",
      "[INFO] Total key frames: 1402 frames\n",
      "\n",
      "[INFO] Total durations and key frame counts have been printed.\n"
     ]
    }
   ],
   "source": [
    "# 비디오, Scene, 모노 오디오 폴더의 총 길이와 키 프레임 수를 출력\n",
    "print_total_durations(preprocessed_video_folder, scene_folder, mono_audio_folder, key_frames_folder)\n",
    "\n",
    "print(f\"\\n[INFO] Total durations and key frame counts have been printed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/junhan/level4-nlp-finalproject-hackathon-nlp-01-lv3/.venv/lib/python3.10/site-packages/clip/clip.py:57: UserWarning: /data/ephemeral/home/.cache/clip/ViT-B-32.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
      "100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 73.6MiB/s]\n",
      "Extracting image embeddings: 100%|██████████| 1402/1402 [00:36<00:00, 38.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings have been updated and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CLIP 모델과 전처리 로드\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# 이미지 경로 설정\n",
    "image_dir = \"./key_frames\"\n",
    "image_paths = [\n",
    "    os.path.join(image_dir, fname)\n",
    "    for fname in os.listdir(image_dir)\n",
    "    if fname.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "# 캐시 파일 경로\n",
    "cache_path = \"./key_frames/image_embeddings_cache.pkl\"\n",
    "\n",
    "# 이미지 임베딩 추출 함수 (병렬 처리 적용)\n",
    "def process_image(path):\n",
    "    image = preprocess(Image.open(path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.encode_image(image).cpu().numpy()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_image_embeddings(image_paths):\n",
    "    embeddings = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(process_image, image_paths),\n",
    "                desc=\"Extracting image embeddings\",\n",
    "                total=len(image_paths),\n",
    "            )\n",
    "        )\n",
    "        embeddings.extend(results)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "# 이미지 임베딩 생성 또는 업데이트\n",
    "image_embeddings = get_image_embeddings(image_paths)\n",
    "with open(cache_path, \"wb\") as f:\n",
    "    pickle.dump(image_embeddings, f)\n",
    "print(\"Image embeddings have been updated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
